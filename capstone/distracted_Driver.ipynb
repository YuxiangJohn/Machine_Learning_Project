{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers data\n",
      "Read train images\n",
      "Load folder c0\n",
      "Load folder c1\n",
      "Load folder c2\n",
      "Load folder c3\n",
      "Load folder c4\n",
      "Load folder c5\n",
      "Load folder c6\n",
      "Load folder c7\n",
      "Load folder c8\n",
      "Load folder c9\n",
      "Read train data time: 177.92 seconds\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "Train shape: (22424, 1, 64, 64)\n",
      "22424 train samples\n",
      "Read test images\n",
      "Read 7972 images from 79726\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "use_cache = 1\n",
    "# color type: 1 - grey, 3 - rgb\n",
    "color_type_global = 1\n",
    "\n",
    "\n",
    "# color_type = 1 - gray\n",
    "# color_type = 3 - RGB\n",
    "def get_im_cv2(path, img_rows, img_cols, color_type=1):\n",
    "    # Load as grayscale\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, 0)\n",
    "    elif color_type == 3:\n",
    "        img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def get_im_cv2_mod(path, img_rows, img_cols, color_type=1):\n",
    "    # Load as grayscale\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, 0)\n",
    "    else:\n",
    "        img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    rotate = random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), rotate, 1)\n",
    "    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "    resized = cv2.resize(img, (img_cols, img_rows), cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "    \n",
    "\n",
    "def get_driver_data():\n",
    "    dr = dict()\n",
    "    path = os.path.join( 'data', 'driver_imgs_list.csv')\n",
    "    print('Read drivers data')\n",
    "    f = open(path, 'r')\n",
    "    line = f.readline()\n",
    "    while (1):\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        arr = line.strip().split(',')\n",
    "        dr[arr[2]] = arr[0]\n",
    "    f.close()\n",
    "    return dr\n",
    "\n",
    "\n",
    "def load_train(img_rows, img_cols, color_type=1):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    driver_id = []\n",
    "    start_time = time.time()\n",
    "    driver_data = get_driver_data()\n",
    "\n",
    "    print('Read train images')\n",
    "    for j in range(10):\n",
    "        print('Load folder c{}'.format(j))\n",
    "        path = os.path.join( 'data','imgs', 'train', 'c' + str(j), '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2_mod(fl, img_rows, img_cols, color_type)\n",
    "            X_train.append(img)\n",
    "            y_train.append(j)\n",
    "            driver_id.append(driver_data[flbase])\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    unique_drivers = sorted(list(set(driver_id)))\n",
    "    print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "    print(unique_drivers)\n",
    "    return X_train, y_train, driver_id, unique_drivers\n",
    "\n",
    "\n",
    "def load_test(img_rows, img_cols, color_type=1):\n",
    "    print('Read test images')\n",
    "    start_time = time.time()\n",
    "    path = os.path.join( 'data', 'imgs','test', '*.jpg')\n",
    "    files = glob.glob(path)\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    total = 0\n",
    "    thr = math.floor(len(files)/10)\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2_mod(fl, img_rows, img_cols, color_type)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "        total += 1\n",
    "        if total%thr == 0:\n",
    "            print('Read {} images from {}'.format(total, len(files)))\n",
    "    \n",
    "    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_test, X_test_id\n",
    "\n",
    "\n",
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')\n",
    "\n",
    "\n",
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_model(model):\n",
    "    json_string = model.to_json()\n",
    "    if not os.path.isdir('cache'):\n",
    "        os.mkdir('cache')\n",
    "    open(os.path.join('cache', 'architecture.json'), 'w').write(json_string)\n",
    "    model.save_weights(os.path.join('cache', 'model_weights.h5'), overwrite=True)\n",
    "\n",
    "\n",
    "def read_model():\n",
    "    model = model_from_json(open(os.path.join('cache', 'architecture.json')).read())\n",
    "    model.load_weights(os.path.join('cache', 'model_weights.h5'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_validation_set(train, target, test_size):\n",
    "    random_state = 51\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)\n",
    "\n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols, color_type=1):\n",
    "    cache_path = os.path.join('cache', 'train_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        train_data, train_target, driver_id, unique_drivers = load_train(img_rows, img_cols, color_type)\n",
    "        cache_data((train_data, train_target, driver_id, unique_drivers), cache_path)\n",
    "    else:\n",
    "        print('Restore train from cache!')\n",
    "        (train_data, train_target, driver_id, unique_drivers) = restore_data(cache_path)\n",
    "\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    train_data = train_data.reshape(train_data.shape[0], color_type, img_rows, img_cols)\n",
    "    train_target = np_utils.to_categorical(train_target, 10)\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data /= 255\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, driver_id, unique_drivers\n",
    "\n",
    "\n",
    "def read_and_normalize_test_data(img_rows, img_cols, color_type=1):\n",
    "    cache_path = os.path.join('cache', 'test_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        test_data, test_id = load_test(img_rows, img_cols, color_type)\n",
    "        cache_data((test_data, test_id), cache_path)\n",
    "    else:\n",
    "        print('Restore test from cache!')\n",
    "        (test_data, test_id) = restore_data(cache_path)\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(test_data.shape[0], color_type, img_rows, img_cols)\n",
    "    test_data = test_data.astype('float32')\n",
    "    test_data /= 255\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    return test_data, test_id\n",
    "\n",
    "\n",
    "def dict_to_list(d):\n",
    "    ret = []\n",
    "    for i in d.items():\n",
    "        ret.append(i[1])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def merge_several_folds_geom(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a *= np.array(data[i])\n",
    "    a = np.power(a, 1/nfolds)\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def copy_selected_drivers(train_data, train_target, driver_id, driver_list):\n",
    "    data = []\n",
    "    target = []\n",
    "    index = []\n",
    "    for i in range(len(driver_id)):\n",
    "        if driver_id[i] in driver_list:\n",
    "            data.append(train_data[i])\n",
    "            target.append(train_target[i])\n",
    "            index.append(i)\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    target = np.array(target, dtype=np.float32)\n",
    "    index = np.array(index, dtype=np.uint32)\n",
    "    return data, target, index\n",
    "\n",
    "\n",
    "def create_model_v1(img_rows, img_cols, color_type=1):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (3, 3), border_mode='same', init='he_normal',\n",
    "                            input_shape=(color_type, img_rows, img_cols)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3), border_mode='same', init='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(128, (3, 3), border_mode='same', init='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(Adam(lr=1e-3), loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_single():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 64, 64\n",
    "    batch_size = 32\n",
    "    nb_epoch = 1\n",
    "    random_state = 51\n",
    "\n",
    "    train_data, train_target, driver_id, unique_drivers = read_and_normalize_train_data(img_rows, img_cols, color_type_global)\n",
    "    test_data, test_id = read_and_normalize_test_data(img_rows, img_cols, color_type_global)\n",
    "\n",
    "    yfull_train = dict()\n",
    "    yfull_test = []\n",
    "    unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024',\n",
    "                     'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049',\n",
    "                     'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072',\n",
    "                     'p075']\n",
    "    X_train, Y_train, train_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_train)\n",
    "    unique_list_valid = ['p081']\n",
    "    X_valid, Y_valid, test_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_valid)\n",
    "\n",
    "    print('Start Single Run')\n",
    "    print('Split train: ', len(X_train), len(Y_train))\n",
    "    print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "    print('Train drivers: ', unique_list_train)\n",
    "    print('Test drivers: ', unique_list_valid)\n",
    "\n",
    "    model = create_model_v1(img_rows, img_cols, color_type_global)\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "    # score = model.evaluate(X_valid, Y_valid, show_accuracy=True, verbose=0)\n",
    "    # print('Score log_loss: ', score[0])\n",
    "\n",
    "    predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "    score = log_loss(Y_valid, predictions_valid)\n",
    "    print('Score log_loss: ', score)\n",
    "\n",
    "    # Store valid predictions\n",
    "    for i in range(len(test_index)):\n",
    "        yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "    # Store test predictions\n",
    "    test_prediction = model.predict(test_data, batch_size=128, verbose=1)\n",
    "    yfull_test.append(test_prediction)\n",
    "\n",
    "    print('Final log_loss: {}, rows: {} cols: {} epoch: {}'.format(score, img_rows, img_cols, nb_epoch))\n",
    "    info_string = 'loss_' + str(score) \\\n",
    "                    + '_r_' + str(img_rows) \\\n",
    "                    + '_c_' + str(img_cols) \\\n",
    "                    + '_ep_' + str(nb_epoch)\n",
    "\n",
    "    test_res = merge_several_folds_mean(yfull_test, 1)\n",
    "    create_submission(test_res, test_id, info_string)\n",
    "\n",
    "\n",
    "run_single()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "\n",
    "use_cache = 1\n",
    "# color type: 1 - grey, 3 - rgb\n",
    "color_type_global = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-240dbf4dcdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'imgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img_34.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# only call close('all') if any to close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# close triggers gc.collect, which can be slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "path = os.path.join( 'data','imgs', 'train', 'c0', 'img_34.jpg')\n",
    "img=cv2.imread(path)\n",
    "plt.show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEICAYAAADMRzbSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKYC+HBVFUQqgL0dFUZQC/H9mCU2zbj4XBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30fc571eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.join( 'data','imgs', 'train', 'c0', 'img_34.jpg')\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread(path)\n",
    "resized = cv2.resize(img, (80, 60), cv2.INTER_LINEAR)\n",
    "plt.title('a')\n",
    "plt.imshow(resized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#module\n",
    "\n",
    "def get_im_cv2(path, img_rows, img_cols, color_type=1):\n",
    "    # Load as grayscale\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, 0)\n",
    "    elif color_type == 3:\n",
    "        img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def get_im_cv2_mod(path, img_rows, img_cols, color_type=1):\n",
    "    # Load as grayscale\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, 0)\n",
    "    else:\n",
    "        img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    #rotate = random.uniform(-10, 10)\n",
    "    #M = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), rotate, 1)\n",
    "    #img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "    resized = cv2.resize(img, (img_cols, img_rows), cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "    \n",
    "\n",
    "def get_driver_data():\n",
    "    dr = dict()\n",
    "    path = os.path.join( 'data', 'driver_imgs_list.csv')\n",
    "    print('Read drivers data')\n",
    "    f = open(path, 'r')\n",
    "    line = f.readline()\n",
    "    while (1):\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        arr = line.strip().split(',')\n",
    "        dr[arr[2]] = arr[0]\n",
    "    f.close()\n",
    "    return dr\n",
    "\n",
    "\n",
    "def load_train(img_rows, img_cols, color_type=1):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    driver_id = []\n",
    "    start_time = time.time()\n",
    "    driver_data = get_driver_data()\n",
    "\n",
    "    print('Read train images')\n",
    "    for j in range(10):\n",
    "        print('Load folder c{}'.format(j))\n",
    "        path = os.path.join( 'data','imgs', 'train', 'c' + str(j), '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files[0:int(len(files)/2)]:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2_mod(fl, img_rows, img_cols, color_type)\n",
    "            X_train.append(img)\n",
    "            y_train.append(j)\n",
    "            driver_id.append(driver_data[flbase])\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    unique_drivers = sorted(list(set(driver_id)))\n",
    "    print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "    print(unique_drivers)\n",
    "    return X_train, y_train, driver_id, unique_drivers\n",
    "\n",
    "\n",
    "def load_test(img_rows, img_cols, color_type=1):\n",
    "    print('Read test images')\n",
    "    start_time = time.time()\n",
    "    path = os.path.join( 'data', 'imgs','test', '*.jpg')\n",
    "    files = glob.glob(path)\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    total = 0\n",
    "    thr = math.floor(len(files)/10)\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2_mod(fl, img_rows, img_cols, color_type)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "        total += 1\n",
    "        if total%thr == 0:\n",
    "            print('Read {} images from {}'.format(total, len(files)))\n",
    "    \n",
    "    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_test, X_test_id\n",
    "\n",
    "\n",
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')\n",
    "\n",
    "\n",
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_model(model):\n",
    "    json_string = model.to_json()\n",
    "    if not os.path.isdir('cache'):\n",
    "        os.mkdir('cache')\n",
    "    open(os.path.join('cache', 'architecture.json'), 'w').write(json_string)\n",
    "    model.save_weights(os.path.join('cache', 'model_weights.h5'), overwrite=True)\n",
    "\n",
    "\n",
    "def read_model():\n",
    "    model = model_from_json(open(os.path.join('cache', 'architecture.json')).read())\n",
    "    model.load_weights(os.path.join('cache', 'model_weights.h5'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_validation_set(train, target, test_size):\n",
    "    random_state = 51\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)\n",
    "\n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols, color_type=1):\n",
    "    cache_path = os.path.join('cache', 'train_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        train_data, train_target, driver_id, unique_drivers = load_train(img_rows, img_cols, color_type)\n",
    "        cache_data((train_data, train_target, driver_id, unique_drivers), cache_path)\n",
    "    else:\n",
    "        print('Restore train from cache!')\n",
    "        (train_data, train_target, driver_id, unique_drivers) = restore_data(cache_path)\n",
    "\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    train_data = train_data.reshape(train_data.shape[0], img_rows, img_cols, color_type)\n",
    "    train_target = np_utils.to_categorical(train_target, 10)\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data /= 255\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, driver_id, unique_drivers\n",
    "\n",
    "\n",
    "def read_and_normalize_test_data(img_rows, img_cols, color_type=1):\n",
    "    cache_path = os.path.join('cache', 'test_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        test_data, test_id = load_test(img_rows, img_cols, color_type)\n",
    "        cache_data((test_data, test_id), cache_path)\n",
    "    else:\n",
    "        print('Restore test from cache!')\n",
    "        (test_data, test_id) = restore_data(cache_path)\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, color_type)\n",
    "    test_data = test_data.astype('float32')\n",
    "    test_data /= 255\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    return test_data, test_id\n",
    "\n",
    "\n",
    "def dict_to_list(d):\n",
    "    ret = []\n",
    "    for i in d.items():\n",
    "        ret.append(i[1])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def merge_several_folds_geom(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a *= np.array(data[i])\n",
    "    a = np.power(a, 1/nfolds)\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def copy_selected_drivers(train_data, train_target, driver_id, driver_list):\n",
    "    data = []\n",
    "    target = []\n",
    "    index = []\n",
    "    for i in range(len(driver_id)):\n",
    "        if driver_id[i] in driver_list:\n",
    "            data.append(train_data[i])\n",
    "            target.append(train_target[i])\n",
    "            index.append(i)\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    target = np.array(target, dtype=np.float32)\n",
    "    index = np.array(index, dtype=np.uint32)\n",
    "    return data, target, index\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import h5py\n",
    "\n",
    "def create_model_v1(img_rows, img_cols, color_type=1):\n",
    "    \n",
    "\n",
    "    \n",
    "    # Block 1\n",
    "    img_input=Input((img_rows, img_cols, color_type))\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "    #img_input=Input((img_rows, img_cols, color_type))\n",
    "    model = Model(input=img_input, output=x)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,150,150)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n",
    "\n",
    "    f = h5py.File('vgg16_weights.h5')\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        # set the weights to layer-k\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "        \n",
    "    print('VGG16 model weights have been successfully loaded.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # build a MLP classifier model to put on top of the VGG16 model\n",
    "    top_model = Sequential()\n",
    "    # flateen the output of VGG16 model to 2D Numpy matrix (n*D)\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    # hidden layer of 256 neurons\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    # add dropout for the dense layer\n",
    "    top_model.add(Dropout(0.5))\n",
    "    # the output layer: we have 10 claases\n",
    "    top_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # connect the two models onto the VGG16 net\n",
    "    model.add(top_model)\n",
    "\n",
    "    # set the first 25 layers (up to the last conv block) of VGFG16 net to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:25]:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(4096, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(4096, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(1000, activation='softmax'))\n",
    "    \n",
    "    #model.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    #model.compile(Adam(lr=1e-3), loss='categorical_crossentropy')\n",
    "    #from keras.applications.resnet50 import ResNet50\n",
    "    #from keras.applications.resnet50 import preprocess_input,decode_predictions\n",
    "    \n",
    "    #model = ResNet50(weigths='imagenet')\n",
    "    \"\"\"\n",
    "    return model\n",
    "\n",
    "def VGG16(include_top=False, weights='imagenet',\n",
    "          input_tensor=None, input_shape=(80,60,3),\n",
    "          pooling=None,\n",
    "          classes=10):\n",
    "   \n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore train from cache!\n",
      "Train shape: (11209, 80, 60, 3)\n",
      "11209 train samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 80, 60\n",
    "batch_size = 32\n",
    "nb_epoch = 20\n",
    "random_state = 51\n",
    "\n",
    "train_data, train_target, driver_id, unique_drivers = read_and_normalize_train_data(img_rows, img_cols, color_type_global)\n",
    "#test_data, test_id = read_and_normalize_test_data(img_rows, img_cols, color_type_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Single Run\n",
      "Split train:  10813 10813\n",
      "Split valid:  396 396\n",
      "Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
      "Test drivers:  ['p081']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected dense_1 to have 4 dimensions, but got array with shape (10813, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-54128a835807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m model.fit(X_train, Y_train, batch_size=batch_size, epochs=100,\n\u001b[0;32m---> 35\u001b[0;31m                verbose=2, validation_data=(X_valid, Y_valid), callbacks = callbacks_list)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1406\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                                     exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1300\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1301\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/john/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected dense_1 to have 4 dimensions, but got array with shape (10813, 10)"
     ]
    }
   ],
   "source": [
    "yfull_train = dict()\n",
    "yfull_test = []\n",
    "unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024',\n",
    "                     'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049',\n",
    "                     'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072',\n",
    "                     'p075']\n",
    "X_train, Y_train, train_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_train)\n",
    "unique_list_valid = ['p081']\n",
    "X_valid, Y_valid, test_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_valid)\n",
    "\n",
    "print('Start Single Run')\n",
    "print('Split train: ', len(X_train), len(Y_train))\n",
    "print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "print('Train drivers: ', unique_list_train)\n",
    "print('Test drivers: ', unique_list_valid)\n",
    "\n",
    "#model = create_model_v1(img_rows, img_cols, color_type_global)\n",
    "#model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "model = Sequential()\n",
    "model.add(VGG16(include_top=False,input_shape=([80,60,3])))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath = \"weights.best.hdf5\"\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list=[checkpoint]\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience = 2)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=100,\n",
    "               verbose=2, validation_data=(X_valid, Y_valid), callbacks = callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 2s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Score log_loss:  2.30111829844\n"
     ]
    }
   ],
   "source": [
    "predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "score = log_loss(Y_valid, predictions_valid)\n",
    "print('Score log_loss: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n",
      "Final log_loss: 1.9352683063491034, rows: 64 cols: 64 epoch: 1\n"
     ]
    }
   ],
   "source": [
    " for i in range(len(test_index)):\n",
    "    yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "    # Store test predictions\n",
    "    test_prediction = model.predict(test_data, batch_size=128)\n",
    "    yfull_test.append(test_prediction)\n",
    "\n",
    "    print('Final log_loss: {}, rows: {} cols: {} epoch: {}'.format(score, img_rows, img_cols, nb_epoch))\n",
    "    info_string = 'loss_' + str(score) \\\n",
    "                    + '_r_' + str(img_rows) \\\n",
    "                    + '_c_' + str(img_cols) \\\n",
    "                    + '_ep_' + str(nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    " img_rows, img_cols = 64, 64\n",
    "    batch_size = 32\n",
    "    nb_epoch = 1\n",
    "    random_state = 51\n",
    "\n",
    "    train_data, train_target, driver_id, unique_drivers = read_and_normalize_train_data(img_rows, img_cols, color_type_global)\n",
    "    test_data, test_id = read_and_normalize_test_data(img_rows, img_cols, color_type_global)\n",
    "\n",
    "    yfull_train = dict()\n",
    "    yfull_test = []\n",
    "    unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024',\n",
    "                     'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049',\n",
    "                     'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072',\n",
    "                     'p075']\n",
    "    X_train, Y_train, train_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_train)\n",
    "    unique_list_valid = ['p081']\n",
    "    X_valid, Y_valid, test_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_valid)\n",
    "\n",
    "    print('Start Single Run')\n",
    "    print('Split train: ', len(X_train), len(Y_train))\n",
    "    print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "    print('Train drivers: ', unique_list_train)\n",
    "    print('Test drivers: ', unique_list_valid)\n",
    "\n",
    "    model = create_model_v1(img_rows, img_cols, color_type_global)\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "    # score = model.evaluate(X_valid, Y_valid, show_accuracy=True, verbose=0)\n",
    "    # print('Score log_loss: ', score[0])\n",
    "\n",
    "    predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "    score = log_loss(Y_valid, predictions_valid)\n",
    "    print('Score log_loss: ', score)\n",
    "\n",
    "    # Store valid predictions\n",
    "    for i in range(len(test_index)):\n",
    "        yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "    # Store test predictions\n",
    "    test_prediction = model.predict(test_data, batch_size=128, verbose=1)\n",
    "    yfull_test.append(test_prediction)\n",
    "\n",
    "    print('Final log_loss: {}, rows: {} cols: {} epoch: {}'.format(score, img_rows, img_cols, nb_epoch))\n",
    "    info_string = 'loss_' + str(score) \\\n",
    "                    + '_r_' + str(img_rows) \\\n",
    "                    + '_c_' + str(img_cols) \\\n",
    "                    + '_ep_' + str(nb_epoch)\n",
    "\n",
    "    test_res = merge_several_folds_mean(yfull_test, 1)\n",
    "    create_submission(test_res, test_id, info_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
